# Cloud LLM Configuration

[cloud]
# API endpoint (OpenAI-compatible)
# OpenAI: https://api.openai.com/v1/chat/completions
# Groq: https://api.groq.com/openai/v1/chat/completions
# Cerebras (FREE, fast): https://api.cerebras.ai/v1/chat/completions
# Together AI (FREE trial): https://api.together.xyz/v1/chat/completions
# Ollama: http://localhost:11434/v1/chat/completions
# ...
api_url = https://api.cerebras.ai/v1/chat/completions

# API key
api_key = YOUR_API_KEY_HERE

# Model name
# gpt-4, gpt-3.5-turbo, llama3.1-8b, llama3.1-70b, grok-4-latest...
model = llama3.1-8b

# Temperature (0.0-2.0, higher = more creative)
temperature = 0.7

# Max tokens to generate
max_tokens = 512
